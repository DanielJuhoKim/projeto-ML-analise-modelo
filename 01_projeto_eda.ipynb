{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b429f9",
   "metadata": {},
   "source": [
    "## Lendo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda96630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from projeto.dataset import read_dataset\n",
    "\n",
    "base_path = Path.cwd()\n",
    "df = read_dataset(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e304b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce251f4",
   "metadata": {},
   "source": [
    "## Análise exploratória preliminar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e4091",
   "metadata": {},
   "source": [
    "Rode o código abaixo e responda:\n",
    "\n",
    "- Todas as colunas estão de acordo com seus respectivos nomes?\n",
    "- Existem dados faltantes?\n",
    "- Para as variáveis contínuas: existem outliers ou anomalias?\n",
    "- Para as variáveis categóricas: existem situações de desbalanceamento severo de classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c31fc9",
   "metadata": {},
   "source": [
    "***Respostas:***\n",
    "\n",
    "1. Analisando os 5 primeiros exemplos mostrados pela função _describe_head() e os gráficos de distribuição gerados, todas features apresentam valores respectivos ao seu nome, tendo o detalhe de que as features capital.gain e capital.loss apresentam valores suspeitos \n",
    "\n",
    "2. Sim, há dados faltantes nas features workclass(1836), occupation(1843) e native.country(583), sendo todas elas features do tipo categóricas/qualitativas\n",
    "\n",
    "3. Usando a função analisador_outlier_num()(Função que está no arquivo funcoes_extras.py) e analisando os gráficos obtidos por run_univariate_EDA(), foi avistado que as features/variáveis contínuas possuem outliers\n",
    "\n",
    "4. Analisando os gráficos obtidos por run_univariate_EDA(), concluí que ocorre sim situações de desbalanceamento severo de classes, um exemplo é no gráfico de education-level distribuition, que mostra a categoria HS-Grade estando muito maior que outras categorias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308091ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a575d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projeto.eda import run_univariate_EDA\n",
    "\n",
    "run_univariate_EDA(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91086cb5",
   "metadata": {},
   "source": [
    "## Filtragem e pré-processamento do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62fc70",
   "metadata": {},
   "source": [
    "Execute o código abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def cut_non_americans(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[df['native.country'] == 'United-States']\n",
    "    df = df.drop(columns=['native.country'])\n",
    "    return df\n",
    "\n",
    "df = cut_non_americans(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5f4db",
   "metadata": {},
   "source": [
    "Responda: qual o motivo para fazer este procedimento?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291a446",
   "metadata": {},
   "source": [
    "***Resposta***:\n",
    "\n",
    "Por 'native.country' ser uma feature de pouca importância e influência, mas que possui dados faltantes, excluímos ela do dataset para evitar erros em relação à falta de dados e impactos negativos no processo de treino do modelo, além disso, o modelo pode acabar se tornando enviesado devido à frequência do número de exemplos com 'native.country' = 'United-States' ser muito maior em relação à outros, o que poderia causar overfitting, por isso, antes de excluir a coluna, mantemos os exemplos que possuem 'native.country' = 'United-States':\n",
    "\n",
    "{'United-States': 29170, nan: 583, 'Mexico': 643, 'Greece': 29,\n",
    "\n",
    "'Vietnam': 67, 'China': 75, 'Taiwan': 51, 'India': 100,\n",
    "\n",
    "'Philippines': 198, 'Trinadad&Tobago': 19, 'Canada': 121,\n",
    "\n",
    "'South': 80, 'Holand-Netherlands': 1, 'Puerto-Rico': 114,\n",
    "\n",
    "'Poland': 60, 'Iran': 43, 'England': 90, 'Germany': 137, 'Italy': 73,\n",
    "\n",
    "'Japan': 62, 'Hong': 20, 'Honduras': 13, 'Cuba': 95, 'Ireland': 24, 'Cambodia': 19,\n",
    "\n",
    "'Peru': 31, 'Nicaragua': 34, 'Dominican-Republic': 70, 'Haiti': 44, 'El-Salvador': 106,\n",
    "\n",
    "'Hungary': 13, 'Columbia': 59, 'Guatemala': 64, 'Jamaica': 81, 'Ecuador': 28,\n",
    "\n",
    "'France': 29, 'Yugoslavia': 16, 'Scotland': 12, 'Portugal': 37, 'Laos': 18, 'Thailand': 18, 'Outlying-US(Guam-USVI-etc)': 14}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde75c7",
   "metadata": {},
   "source": [
    "## Separação treino-teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f570b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['income'])\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projeto.config import RANDOM_SEED, TEST_SIZE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810fdbb",
   "metadata": {},
   "source": [
    "## Análise pós-separação treino-teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440da20",
   "metadata": {},
   "source": [
    "Nem todos os pares de colunas merecem uma análise conjunta detalhada, isso rapidamente foge ao controle. Vamos privilegiar inicialmente:\n",
    "\n",
    "- Análise descritiva:\n",
    "\n",
    "    - Correlação entre *features* para identificar possiveis colinearidades simples e outras redundâncias de informação:\n",
    "\n",
    "        - Entre *features* numéricas: correlação (e.g. Pearson)\n",
    "\n",
    "        - Entre *features* categóricas: coeficiente de associação (e.g. [coeficiente V de Cramer](https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V))\n",
    "\n",
    "        - Entre uma *feature* categórica e uma contínua: podemos *discretizar* a *feature* contínua por quantis e tratar esse problema como sendo um problema de associação entre categóricas, mas é meio gambiarra isso... paciencia. \n",
    "\n",
    "    - Correlação entre *target* e *features*, para identificar possíveis *features* que sejam:\n",
    "    \n",
    "        - Perfeitamente preditoras do target: isso é um sinal de que o *target* e a *feature* são a mesma coisa, e fazer um projeto de *machine learning* para prever $y$ à partir de... $y$ (!) é obviamente perda de tempo e dinheiro.\n",
    "\n",
    "        - Totalmente não-correlacionadas com o target: *TALVEZ* indique que a *feature* em questão é inútil, mas isso nem sempre é verdade. Pode ser que a *feature* tem o seu valor preditivo apenas quando combinada com outras features. Pode ser que esta *feature* tenha um valor preditivo perfeito, e que a correlação se mostra baixa apenas porque a relação entre esta *feature* e o *target* é não-linear (e portanto não vai ser percebida pela correlação de Pearson).\n",
    "\n",
    "- Visualização:\n",
    "\n",
    "    - Ver os gráficos apropriados para a visualização conjunta de *target* e cada *feature*, e de pares de *features* que chamaram a atenção na análise descritiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3a8635",
   "metadata": {},
   "source": [
    "Rode o código abaixo e responda as seguintes questões:\n",
    "\n",
    "- Liste 3 *features* que parecem ter alta associação com o *target*\n",
    "- O que acontece com as variáveis `capital.gain` e `capital.loss`? Explique. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e100c56a",
   "metadata": {},
   "source": [
    "***Resposta***:\n",
    "\n",
    "* Analisando os resultados obtidos pela função run_joint_EDA(), usando os dados de treino e os originais, as features com maior associação ao target(Income):\n",
    "    - marital.status\n",
    "    - education\n",
    "    - relationship\n",
    "\n",
    "* `capital.gain` e `capital.loss`\n",
    "\n",
    "Ambas as fatures são descartadas devido à forma de como seus dados são distribuídos, algo que pode-se ver nos gráficos de distribuição de Capital Gain e Capital Loss acima, onde ambas as features são composta por 0 na maioria das vezes\n",
    "\n",
    "Por causa disso, não usamos essas features, já que ao tentar fazer o modelo usá-las para obter o target, poderia acabar fazendo o modelo ficar muito enviesado, o que por consequência, causaria overfitting nas predições do modelo quando o modelo obtesse um valor que é diferente de 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projeto.eda import run_joint_EDA\n",
    "\n",
    "run_joint_EDA(X_train, y_train)\n",
    "# run_joint_EDA(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e926e",
   "metadata": {},
   "source": [
    "# Gravando os arquivos de dados\n",
    "\n",
    "Por fim, vamos gravar em disco os arquivos de dados resultantes da nossa análise, isso é fundamental!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbe57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projeto.dataset import save_processed_datasets\n",
    "\n",
    "save_processed_datasets(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    base_path=base_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceab8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "workclass\n",
      "education\n",
      "education.num\n",
      "marital.status\n",
      "occupation\n",
      "relationship\n",
      "race\n",
      "sex\n",
      "capital.gain\n",
      "capital.loss\n",
      "hours.per.week\n",
      "income\n"
     ]
    }
   ],
   "source": [
    "for data in df:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d06e3",
   "metadata": {},
   "source": [
    "Responda: o que aconteceria se ao invés de gravar estes arquivos, fizéssemos a leitura do arquivo original e uma simples separação treino-teste no *notebook* de modelagem, sem maiores cuidados?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfee328",
   "metadata": {},
   "source": [
    "***Resposta***:\n",
    "\n",
    "Ao ter features irrelevantes com falta de dados ou dados incorretos/pouca variação, faria o modelo se tornar enviesado e instável, obtendo predições que poderiam causar overfitting/underfitting e/ou imprecisos/incorretos\n",
    "\n",
    "Além de também não saber quais features o modelo teria que priorizar ao fazer a predição, um exemplo seria se um dos fatores decisivos do modelo fosse o 'native-country', ao ter essa feature como um fator decisivo, o modelo desconsideraria features com maior relevância ao target e acabaria por causar overfitting devido ao fato de que maioria dos dados do 'native-country' são 'United-States'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d421414",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619994fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alglin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
